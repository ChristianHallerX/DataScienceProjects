{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music-Genre Classification with KNN\n",
    "\n",
    "## Goal\n",
    "\n",
    "This project will develop a deep learning model to infer music genres from audio files.\n",
    "\n",
    "We will classify training-set audio files using their low-level features of *frequency* and *time domain*.\n",
    "\n",
    "Training the model requires audio tracks having similar size and similar frequency range. The **GTZAN** genre classification dataset is a useful dataset for such purpose, since it was collected for this task specifically.\n",
    "\n",
    "## Data\n",
    "\n",
    "The GTZAN was collected 2000-2001 and named after its curator George Tzanetaki. More here: http://marsyas.info/downloads/datasets.html. The dataset consists of 1000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050Hz Mono 16-bit audio files in .wav format. The collection is ca. 1.2 gigabyte.\n",
    "\n",
    "- Blues\n",
    "- Classical\n",
    "- Country\n",
    "- Disco\n",
    "- Hiphop\n",
    "- Jazz\n",
    "- Metal\n",
    "- Pop\n",
    "- Reggae\n",
    "- Rock\n",
    "\n",
    "## Feature Extraction with Mel Frequency Cepstral Coefficients (MFCC)\n",
    "\n",
    "The classification will be based on the vocal content exclusively. This requires identifying the linguistic content and discarding noise.\n",
    "\n",
    "MFCC are state-of-the-art features used in automatic speech and speech recognition studies. There are a set of steps:\n",
    "\n",
    "1. Since the audio signals are constantly changing, divide these signals into smaller frames. Each frame is around 20-40 ms long.\n",
    "2. Identify frequencies present in each frame.\n",
    "3. Separate linguistic frequencies from noise.\n",
    "4. To discard the noise, it then takes Discrete Cosine Transform (DCT) of these frequencies. Keep only a specific sequence of frequencies that have a high probability of information.\n",
    "\n",
    "## ML Methods\n",
    "\n",
    "We will use K-nearest neighbors (KNN) algorithm because it has shown the best results for this problem.\n",
    "\n",
    "## Samples for Prediction\n",
    "\n",
    "Music samples are available here: https://freemusicarchive.org/ \n",
    "The tracks are tagged by genre, but most authors categorize their work as multi-genre. Almost no tracks are unequivocally a single genre.\n",
    "\n",
    "Most audio is available as mp3 today, use the following web app to convert to wav:\n",
    "https://audio.online-convert.com/convert-to-wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "import pickle\n",
    "import random \n",
    "import operator\n",
    "import math\n",
    "import wget\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download GTZAN and Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists\n"
     ]
    }
   ],
   "source": [
    "url = 'http://opihi.cs.uvic.ca/sound/genres.tar.gz'\n",
    "out_path = f'{os.getcwd()}\\\\Data\\\\genres.tar.gz'\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    wget.download(url, out=out_path)\n",
    "    print(\"Download finished\")\n",
    "else:\n",
    "    print(\"File exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTZANtar = tarfile.open(out_path)\n",
    "GTZANtar.extractall(f'{os.getcwd()}\\\\Data\\\\')\n",
    "GTZANtar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract features, save to .dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'{os.getcwd()}\\\\Data\\\\genres'\n",
    "f = open(f'{os.getcwd()}\\\\Data\\\\genre_features.dat' ,'wb') # dat file to be written\n",
    "i = 0\n",
    "\n",
    "for folder in [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]: # iterate over genre folders only\n",
    "    i += 1\n",
    "    if i == 11:\n",
    "        break\n",
    "    for file in os.listdir(os.path.join(directory, folder)): # iterate over files in each genre folder\n",
    "        (rate,sig) =  wav.read(os.path.join(directory, folder, file))\n",
    "        mfcc_feat =   mfcc(sig,rate,winlen=0.020,appendEnergy = False)\n",
    "        covariance =  np.cov(np.matrix.transpose(mfcc_feat))\n",
    "        mean_matrix = mfcc_feat.mean(0)\n",
    "        feature =     (mean_matrix,covariance,i)\n",
    "        pickle.dump(feature,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_ds = []\n",
    "\n",
    "def loadDataset(filename, split, trSet, teSet):\n",
    "    with open(filename, 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                loaded_ds.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break\n",
    "    for x in range(len(loaded_ds)):\n",
    "        if random.random() < split:   \n",
    "            trSet.append(loaded_ds[x])\n",
    "        else:\n",
    "            teSet.append(loaded_ds[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = []\n",
    "testSet = []\n",
    "split = 0.66\n",
    "\n",
    "loadDataset(filename=f'{os.getcwd()}\\\\Data\\\\genres\\\\genre_features.dat', split=split, trSet=trainingSet, teSet=testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Helper Functions for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance between feature vectors and find neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(instance1, instance2, k):\n",
    "    distance = 0 \n",
    "    mm1 = instance1[0] \n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "    \n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1)) \n",
    "    distance += (np.dot(np.dot((mm2-mm1).transpose() , np.linalg.inv(cm2)) , mm2-mm1 )) \n",
    "    distance += np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    distance -= k\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(trainingSet, instance, k):\n",
    "    distances = []\n",
    "\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = distance(trainingSet[x], instance, k) + distance(instance, trainingSet[x], k)\n",
    "        distances.append((trainingSet[x][2], dist))\n",
    "\n",
    "    distances.sort(key = operator.itemgetter(1))\n",
    "\n",
    "    neighbors = []\n",
    "\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the nearest Class of the neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestClass(neighbors):\n",
    "    classVote = {}\n",
    "\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVote:\n",
    "            classVote[response]+=1 \n",
    "        else:\n",
    "            classVote[response]=1\n",
    "\n",
    "    sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    return sorter[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "\n",
    "    for x in range (len(testSet)):\n",
    "        if testSet[x][-1]==predictions[x]:\n",
    "            correct+=1\n",
    "\n",
    "    return 1.0*correct/len(testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train KNN  on test data and get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6422287390029325\n"
     ]
    }
   ],
   "source": [
    "length_test = len(testSet)\n",
    "predictions = []\n",
    "\n",
    "for x in range(length_test):\n",
    "    predictions.append(nearestClass(getNeighbors(trainingSet=trainingSet, instance=testSet[x], k=5))) \n",
    "\n",
    "train_accuracy = getAccuracy(testSet, predictions)\n",
    "print(\"Train Accuracy: \", train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Predict genre on wav files\n",
    "\n",
    "I conveniently added the genre tag to the file name for comparison with the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {1: 'blues', 2: 'classical', 3: 'country', 4: 'disco', 5: 'hiphop', 6: 'jazz', 7: 'metal', 8: 'pop', 9: 'reggae', 10: 'rock'})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(int)\n",
    "i = 1\n",
    "\n",
    "for folder in [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]:\n",
    "    results[i]=folder\n",
    "    i+=1\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Blues_Pierce_Murphy_-_02_-_Just_Give_It_Time.wav   ->   country\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Blues_Pierce_Murphy_-_03_-_Try_To_Be_Nice.wav   ->   country\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Country_Derek_Clegg_-_03_-_Peculiar.wav   ->   hiphop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Country_Thorn__Shout_-_06_-_Little_Demon.wav   ->   pop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Disco_Fhernando_-_07_-_Kiss_Me_Harder_Boy.wav   ->   hiphop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Disco_Miami_Slice_-_04_-_Solid_Gold.wav   ->   pop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Reggae_Dieumba__Bass_Culture_Players_-_01_-_Sin_Papeles.wav   ->   hiphop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Reggae_Negritage_ft_Jam_York_-_09_-_Stuck_ina_Babylon.wav   ->   pop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Rock_Cult_Fantastic_-_02_-_Animal.wav   ->   pop\n",
      "File: Rock_JG_Hackett_-_01_-_Bootleg_Romanticism.wav   ->   pop\n"
     ]
    }
   ],
   "source": [
    "prediction_folder = f'{os.getcwd()}\\\\Data\\\\genres_predict\\\\'\n",
    "\n",
    "for file in os.listdir(prediction_folder):\n",
    "    (rate,sig) = wav.read(prediction_folder + file)\n",
    "\n",
    "    # extract the features of the new file\n",
    "    mfcc_feat = mfcc(sig,rate,winlen=0.020,appendEnergy=False)\n",
    "    covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "    mean_matrix = mfcc_feat.mean(0)\n",
    "    feature = (mean_matrix,covariance,0)\n",
    "\n",
    "    pred = nearestClass(getNeighbors(trainingSet=loaded_ds, instance=feature, k=5))\n",
    "    print(\"File: \" + file + '   ->   ' + results[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "It is obvious above, the predictiosn do not match the given genre tags very well.\n",
    "\n",
    "## An explanation:\n",
    "\n",
    "The selected tracks for prediction may be unrepresentative of the genres as they were trained. The training set is from the time 2000/2001. Music genres have progressed. The samples are 20 years newer. Style, taste, sound, may have changed significantly in these genres and the model is not generalized enough to catch the new tracks.\n",
    "\n",
    "Another issue: Cross-genre tracks, as described by the artists on the website, carry multiple traits. However, they have to fall into a single genre in our model.\n",
    "\n",
    "The prediction should be repeated with track from that period to prove its power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
