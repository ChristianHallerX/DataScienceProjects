{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing and tuning a Deep Learning framwork with Grid Search\n",
    "\n",
    "In this case we will simply use the MNIST, since ist is conveniently loaded from Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# load and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a simple model and Grid Search\n",
    "\n",
    "We will choose the best Activation function for the first layer and the optimizer function for the parameters. The grid will be #activation (3) * #optimizers (7) = 21. This is solved with nested loops.\n",
    "\n",
    "Let's save the scores for each hyper parameter and then we can carry on with the best performing hyper parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 17:12:16.247957  5180 deprecation_wrapper.py:119] From C:\\Users\\ChristianV700\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0817 17:12:16.263594  5180 deprecation_wrapper.py:119] From C:\\Users\\ChristianV700\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0817 17:12:16.263594  5180 deprecation_wrapper.py:119] From C:\\Users\\ChristianV700\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0817 17:12:16.294851  5180 deprecation_wrapper.py:119] From C:\\Users\\ChristianV700\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0817 17:12:16.310469  5180 deprecation_wrapper.py:119] From C:\\Users\\ChristianV700\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0817 17:12:16.419791  5180 deprecation.py:323] From C:\\Users\\ChristianV700\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 of 21. Hyperparams: rmsprop, sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0817 17:12:16.482302  5180 deprecation_wrapper.py:119] From C:\\Users\\ChristianV700\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4312 - acc: 0.8847 - val_loss: 0.2718 - val_acc: 0.9227\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2341 - acc: 0.9316 - val_loss: 0.2043 - val_acc: 0.9400\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1773 - acc: 0.9482 - val_loss: 0.1607 - val_acc: 0.9500\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1389 - acc: 0.9598 - val_loss: 0.1319 - val_acc: 0.9613\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1122 - acc: 0.9672 - val_loss: 0.1130 - val_acc: 0.9672\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0921 - acc: 0.9734 - val_loss: 0.0959 - val_acc: 0.9694\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0776 - acc: 0.9776 - val_loss: 0.0922 - val_acc: 0.9706\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0666 - acc: 0.9808 - val_loss: 0.0805 - val_acc: 0.9765\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0571 - acc: 0.9830 - val_loss: 0.0815 - val_acc: 0.9760\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0495 - acc: 0.9856 - val_loss: 0.0756 - val_acc: 0.9770\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0431 - acc: 0.9876 - val_loss: 0.0746 - val_acc: 0.9788\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0377 - acc: 0.9893 - val_loss: 0.0721 - val_acc: 0.9787\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0323 - acc: 0.9912 - val_loss: 0.0670 - val_acc: 0.9797\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0288 - acc: 0.9921 - val_loss: 0.0658 - val_acc: 0.9804\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0250 - acc: 0.9933 - val_loss: 0.0708 - val_acc: 0.9783\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0215 - acc: 0.9946 - val_loss: 0.0681 - val_acc: 0.9801\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0187 - acc: 0.9955 - val_loss: 0.0657 - val_acc: 0.9811\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0164 - acc: 0.9961 - val_loss: 0.0634 - val_acc: 0.9812\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0652 - val_acc: 0.9809\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0124 - acc: 0.9972 - val_loss: 0.0636 - val_acc: 0.9826\n",
      "Model 2 of 21. Hyperparams: adagrad, sigmoid\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.4069 - acc: 0.8890 - val_loss: 0.2830 - val_acc: 0.9184\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2729 - acc: 0.9227 - val_loss: 0.2498 - val_acc: 0.9293\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2440 - acc: 0.9307 - val_loss: 0.2309 - val_acc: 0.9329\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2242 - acc: 0.9357 - val_loss: 0.2151 - val_acc: 0.9391\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2095 - acc: 0.9402 - val_loss: 0.2037 - val_acc: 0.9413\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1973 - acc: 0.9439 - val_loss: 0.1935 - val_acc: 0.9442\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1872 - acc: 0.9470 - val_loss: 0.1870 - val_acc: 0.9462\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1784 - acc: 0.9491 - val_loss: 0.1788 - val_acc: 0.9480\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1709 - acc: 0.9510 - val_loss: 0.1718 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1642 - acc: 0.9533 - val_loss: 0.1663 - val_acc: 0.9525\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1580 - acc: 0.9550 - val_loss: 0.1609 - val_acc: 0.9534\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1526 - acc: 0.9570 - val_loss: 0.1580 - val_acc: 0.9552\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1475 - acc: 0.9577 - val_loss: 0.1536 - val_acc: 0.9547\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1429 - acc: 0.9592 - val_loss: 0.1497 - val_acc: 0.9576\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1388 - acc: 0.9606 - val_loss: 0.1468 - val_acc: 0.9576\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1348 - acc: 0.9620 - val_loss: 0.1425 - val_acc: 0.9587\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1312 - acc: 0.9625 - val_loss: 0.1398 - val_acc: 0.9604\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1277 - acc: 0.9639 - val_loss: 0.1374 - val_acc: 0.9602\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1246 - acc: 0.9645 - val_loss: 0.1353 - val_acc: 0.9606\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1215 - acc: 0.9654 - val_loss: 0.1320 - val_acc: 0.9618\n",
      "Model 3 of 21. Hyperparams: adadelta, sigmoid\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.5507 - acc: 0.8589 - val_loss: 0.3222 - val_acc: 0.9086\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.3120 - acc: 0.9095 - val_loss: 0.2730 - val_acc: 0.9220\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2738 - acc: 0.9206 - val_loss: 0.2509 - val_acc: 0.9290\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2430 - acc: 0.9298 - val_loss: 0.2262 - val_acc: 0.9345\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2148 - acc: 0.9387 - val_loss: 0.2051 - val_acc: 0.9404\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1896 - acc: 0.9459 - val_loss: 0.1850 - val_acc: 0.9437\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1689 - acc: 0.9508 - val_loss: 0.1738 - val_acc: 0.9487\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1516 - acc: 0.9565 - val_loss: 0.1452 - val_acc: 0.9564\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1363 - acc: 0.9605 - val_loss: 0.1347 - val_acc: 0.9596\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1237 - acc: 0.9644 - val_loss: 0.1241 - val_acc: 0.9631\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1124 - acc: 0.9681 - val_loss: 0.1161 - val_acc: 0.9648\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1032 - acc: 0.9700 - val_loss: 0.1090 - val_acc: 0.9657\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0952 - acc: 0.9729 - val_loss: 0.1136 - val_acc: 0.9658\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0881 - acc: 0.9749 - val_loss: 0.0988 - val_acc: 0.9699\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0819 - acc: 0.9761 - val_loss: 0.0971 - val_acc: 0.9716\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0761 - acc: 0.9784 - val_loss: 0.0944 - val_acc: 0.9704\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0712 - acc: 0.9799 - val_loss: 0.0905 - val_acc: 0.9729\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0665 - acc: 0.9812 - val_loss: 0.0942 - val_acc: 0.9710\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0627 - acc: 0.9820 - val_loss: 0.0841 - val_acc: 0.9746\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0584 - acc: 0.9838 - val_loss: 0.0798 - val_acc: 0.9747\n",
      "Model 4 of 21. Hyperparams: adam, sigmoid\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.4509 - acc: 0.8799 - val_loss: 0.2737 - val_acc: 0.9207\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2474 - acc: 0.9285 - val_loss: 0.2123 - val_acc: 0.9393\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1939 - acc: 0.9434 - val_loss: 0.1712 - val_acc: 0.9502\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1552 - acc: 0.9546 - val_loss: 0.1424 - val_acc: 0.9591\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1268 - acc: 0.9630 - val_loss: 0.1233 - val_acc: 0.9625\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1047 - acc: 0.9699 - val_loss: 0.1105 - val_acc: 0.9662\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0865 - acc: 0.9750 - val_loss: 0.1001 - val_acc: 0.9700\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0732 - acc: 0.9793 - val_loss: 0.0915 - val_acc: 0.9718\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0620 - acc: 0.9823 - val_loss: 0.0829 - val_acc: 0.9748\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0534 - acc: 0.9850 - val_loss: 0.0782 - val_acc: 0.9767\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0451 - acc: 0.9877 - val_loss: 0.0719 - val_acc: 0.9775\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0382 - acc: 0.9898 - val_loss: 0.0695 - val_acc: 0.9801\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0320 - acc: 0.9919 - val_loss: 0.0690 - val_acc: 0.9800\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0276 - acc: 0.9931 - val_loss: 0.0664 - val_acc: 0.9802\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0231 - acc: 0.9947 - val_loss: 0.0660 - val_acc: 0.9801\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0195 - acc: 0.9959 - val_loss: 0.0696 - val_acc: 0.9787\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0167 - acc: 0.9966 - val_loss: 0.0629 - val_acc: 0.9815\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0137 - acc: 0.9977 - val_loss: 0.0656 - val_acc: 0.9806\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0113 - acc: 0.9984 - val_loss: 0.0642 - val_acc: 0.9810\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0097 - acc: 0.9987 - val_loss: 0.0656 - val_acc: 0.9809\n",
      "Model 5 of 21. Hyperparams: Nadam, sigmoid\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3761 - acc: 0.8956 - val_loss: 0.2294 - val_acc: 0.9328\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1917 - acc: 0.9443 - val_loss: 0.1546 - val_acc: 0.9544\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1329 - acc: 0.9619 - val_loss: 0.1188 - val_acc: 0.9639\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0978 - acc: 0.9724 - val_loss: 0.0988 - val_acc: 0.9708\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0747 - acc: 0.9783 - val_loss: 0.0896 - val_acc: 0.9721\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0572 - acc: 0.9831 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0440 - acc: 0.9876 - val_loss: 0.0710 - val_acc: 0.9775\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0340 - acc: 0.9906 - val_loss: 0.0738 - val_acc: 0.9764\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0258 - acc: 0.9933 - val_loss: 0.0676 - val_acc: 0.9795\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0196 - acc: 0.9955 - val_loss: 0.0703 - val_acc: 0.9786\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0150 - acc: 0.9971 - val_loss: 0.0607 - val_acc: 0.9811\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0113 - acc: 0.9980 - val_loss: 0.0643 - val_acc: 0.9809\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0085 - acc: 0.9987 - val_loss: 0.0658 - val_acc: 0.9805\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0067 - acc: 0.9990 - val_loss: 0.0665 - val_acc: 0.9816\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0653 - val_acc: 0.9815\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.0639 - val_acc: 0.9816\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0658 - val_acc: 0.9816\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0689 - val_acc: 0.9817\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0682 - val_acc: 0.9810\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0792 - val_acc: 0.9791\n",
      "Model 6 of 21. Hyperparams: Adamax, sigmoid\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.4838 - acc: 0.8738 - val_loss: 0.3025 - val_acc: 0.9159\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2828 - acc: 0.9191 - val_loss: 0.2468 - val_acc: 0.9279\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2371 - acc: 0.9314 - val_loss: 0.2153 - val_acc: 0.9369\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1997 - acc: 0.9419 - val_loss: 0.1824 - val_acc: 0.9459\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1698 - acc: 0.9516 - val_loss: 0.1595 - val_acc: 0.9544\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1463 - acc: 0.9580 - val_loss: 0.1422 - val_acc: 0.9576\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1275 - acc: 0.9640 - val_loss: 0.1247 - val_acc: 0.9631\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1118 - acc: 0.9684 - val_loss: 0.1139 - val_acc: 0.9645\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0990 - acc: 0.9723 - val_loss: 0.1079 - val_acc: 0.9678\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0883 - acc: 0.9754 - val_loss: 0.1004 - val_acc: 0.9691\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0801 - acc: 0.9768 - val_loss: 0.0921 - val_acc: 0.9728\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0718 - acc: 0.9801 - val_loss: 0.0881 - val_acc: 0.9735\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.981 - 2s 32us/step - loss: 0.0657 - acc: 0.9817 - val_loss: 0.0845 - val_acc: 0.9733\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0599 - acc: 0.9834 - val_loss: 0.0793 - val_acc: 0.9762\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0545 - acc: 0.9851 - val_loss: 0.0756 - val_acc: 0.9761\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0502 - acc: 0.9864 - val_loss: 0.0752 - val_acc: 0.9776\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0456 - acc: 0.9879 - val_loss: 0.0731 - val_acc: 0.9770\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0423 - acc: 0.9887 - val_loss: 0.0706 - val_acc: 0.9777\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0389 - acc: 0.9902 - val_loss: 0.0670 - val_acc: 0.9794\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0358 - acc: 0.9908 - val_loss: 0.0688 - val_acc: 0.9796\n",
      "Model 7 of 21. Hyperparams: SGD, sigmoid\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.9473 - acc: 0.5504 - val_loss: 1.6096 - val_acc: 0.7225\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 1.3791 - acc: 0.7642 - val_loss: 1.1546 - val_acc: 0.8031\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 1.0305 - acc: 0.8097 - val_loss: 0.8921 - val_acc: 0.8318\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.8318 - acc: 0.8320 - val_loss: 0.7414 - val_acc: 0.8498\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.7126 - acc: 0.8463 - val_loss: 0.6476 - val_acc: 0.8573\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.6351 - acc: 0.8549 - val_loss: 0.5846 - val_acc: 0.8632\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.5808 - acc: 0.8619 - val_loss: 0.5382 - val_acc: 0.8738\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.5411 - acc: 0.8675 - val_loss: 0.5040 - val_acc: 0.8786\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.5105 - acc: 0.8721 - val_loss: 0.4771 - val_acc: 0.8819\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.4863 - acc: 0.8758 - val_loss: 0.4555 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4667 - acc: 0.8785 - val_loss: 0.4385 - val_acc: 0.8868\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4506 - acc: 0.8818 - val_loss: 0.4239 - val_acc: 0.8889\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4370 - acc: 0.8840 - val_loss: 0.4111 - val_acc: 0.8907\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4252 - acc: 0.8860 - val_loss: 0.4013 - val_acc: 0.8929\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4151 - acc: 0.8878 - val_loss: 0.3915 - val_acc: 0.8933\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.4064 - acc: 0.8890 - val_loss: 0.3845 - val_acc: 0.8949\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3984 - acc: 0.8909 - val_loss: 0.3772 - val_acc: 0.8975\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3915 - acc: 0.8922 - val_loss: 0.3699 - val_acc: 0.8977\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3852 - acc: 0.8930 - val_loss: 0.3644 - val_acc: 0.8997\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3797 - acc: 0.8942 - val_loss: 0.3598 - val_acc: 0.8999\n",
      "Model 8 of 21. Hyperparams: rmsprop, tanh\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.3329 - acc: 0.9024 - val_loss: 0.2242 - val_acc: 0.9374\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1775 - acc: 0.9471 - val_loss: 0.1382 - val_acc: 0.9593\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1173 - acc: 0.9659 - val_loss: 0.1124 - val_acc: 0.9655\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0855 - acc: 0.9747 - val_loss: 0.0892 - val_acc: 0.9734\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0655 - acc: 0.9811 - val_loss: 0.0839 - val_acc: 0.9735\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0510 - acc: 0.9843 - val_loss: 0.0802 - val_acc: 0.9760\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0414 - acc: 0.9872 - val_loss: 0.0763 - val_acc: 0.9766\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0324 - acc: 0.9905 - val_loss: 0.0632 - val_acc: 0.9805\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0261 - acc: 0.9926 - val_loss: 0.0638 - val_acc: 0.9806\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0206 - acc: 0.9944 - val_loss: 0.0591 - val_acc: 0.9823\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0158 - acc: 0.9960 - val_loss: 0.0646 - val_acc: 0.9825\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.0718 - val_acc: 0.9787\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0644 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0698 - val_acc: 0.9802\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0693 - val_acc: 0.9803\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.0653 - val_acc: 0.9820\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.0683 - val_acc: 0.9824\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0762 - val_acc: 0.9810\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0692 - val_acc: 0.9824\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0724 - val_acc: 0.9829\n",
      "Model 9 of 21. Hyperparams: adagrad, tanh\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.3280 - acc: 0.9078 - val_loss: 0.2278 - val_acc: 0.9359\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2089 - acc: 0.9409 - val_loss: 0.1876 - val_acc: 0.9454\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1732 - acc: 0.9511 - val_loss: 0.1649 - val_acc: 0.9520\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1504 - acc: 0.9577 - val_loss: 0.1539 - val_acc: 0.9556\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1342 - acc: 0.9628 - val_loss: 0.1371 - val_acc: 0.9603\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1214 - acc: 0.9668 - val_loss: 0.1274 - val_acc: 0.9634\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1113 - acc: 0.9691 - val_loss: 0.1198 - val_acc: 0.9667\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1028 - acc: 0.9716 - val_loss: 0.1142 - val_acc: 0.9669\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0956 - acc: 0.9742 - val_loss: 0.1102 - val_acc: 0.9683\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0897 - acc: 0.9759 - val_loss: 0.1053 - val_acc: 0.9686\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0844 - acc: 0.9776 - val_loss: 0.1005 - val_acc: 0.9700\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0796 - acc: 0.9786 - val_loss: 0.0990 - val_acc: 0.9704\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0755 - acc: 0.9801 - val_loss: 0.0955 - val_acc: 0.9720\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0717 - acc: 0.9814 - val_loss: 0.0923 - val_acc: 0.9718\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0682 - acc: 0.9822 - val_loss: 0.0904 - val_acc: 0.9726\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0653 - acc: 0.9832 - val_loss: 0.0887 - val_acc: 0.9729\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0623 - acc: 0.9837 - val_loss: 0.0879 - val_acc: 0.9736\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0595 - acc: 0.9846 - val_loss: 0.0851 - val_acc: 0.9744\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0572 - acc: 0.9852 - val_loss: 0.0837 - val_acc: 0.9748\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0549 - acc: 0.9857 - val_loss: 0.0829 - val_acc: 0.9747\n",
      "Model 10 of 21. Hyperparams: adadelta, tanh\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3658 - acc: 0.8956 - val_loss: 0.2605 - val_acc: 0.9252\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2178 - acc: 0.9370 - val_loss: 0.1769 - val_acc: 0.9479\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1530 - acc: 0.9558 - val_loss: 0.1284 - val_acc: 0.9616\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1168 - acc: 0.9661 - val_loss: 0.1131 - val_acc: 0.9660\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0931 - acc: 0.9735 - val_loss: 0.1005 - val_acc: 0.9693\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0760 - acc: 0.9783 - val_loss: 0.0864 - val_acc: 0.9738\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0639 - acc: 0.9816 - val_loss: 0.0820 - val_acc: 0.9743\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0543 - acc: 0.9842 - val_loss: 0.0741 - val_acc: 0.9768\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0461 - acc: 0.9868 - val_loss: 0.0723 - val_acc: 0.9776\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0389 - acc: 0.9893 - val_loss: 0.0716 - val_acc: 0.9777\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0335 - acc: 0.9911 - val_loss: 0.0653 - val_acc: 0.9801\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0286 - acc: 0.9925 - val_loss: 0.0614 - val_acc: 0.9811\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0247 - acc: 0.9939 - val_loss: 0.0618 - val_acc: 0.9809\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0212 - acc: 0.9949 - val_loss: 0.0636 - val_acc: 0.9793\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0180 - acc: 0.9963 - val_loss: 0.0627 - val_acc: 0.9810\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0156 - acc: 0.9969 - val_loss: 0.0583 - val_acc: 0.9815\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0134 - acc: 0.9975 - val_loss: 0.0566 - val_acc: 0.9828\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0114 - acc: 0.9981 - val_loss: 0.0576 - val_acc: 0.9818\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0099 - acc: 0.9986 - val_loss: 0.0598 - val_acc: 0.9815\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0083 - acc: 0.9991 - val_loss: 0.0574 - val_acc: 0.9824\n",
      "Model 11 of 21. Hyperparams: adam, tanh\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3264 - acc: 0.9046 - val_loss: 0.2161 - val_acc: 0.9359\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1783 - acc: 0.9484 - val_loss: 0.1522 - val_acc: 0.9554\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1224 - acc: 0.9640 - val_loss: 0.1161 - val_acc: 0.9658\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0889 - acc: 0.9738 - val_loss: 0.0936 - val_acc: 0.9709\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0672 - acc: 0.9800 - val_loss: 0.0895 - val_acc: 0.9734\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0522 - acc: 0.9849 - val_loss: 0.0762 - val_acc: 0.9768\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0407 - acc: 0.9884 - val_loss: 0.0703 - val_acc: 0.9790\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0322 - acc: 0.9907 - val_loss: 0.0710 - val_acc: 0.9784\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0241 - acc: 0.9941 - val_loss: 0.0650 - val_acc: 0.9802\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0184 - acc: 0.9958 - val_loss: 0.0714 - val_acc: 0.9774\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0144 - acc: 0.9970 - val_loss: 0.0690 - val_acc: 0.9789\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0112 - acc: 0.9979 - val_loss: 0.0641 - val_acc: 0.9806\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0077 - acc: 0.9988 - val_loss: 0.0685 - val_acc: 0.9797\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0066 - acc: 0.9989 - val_loss: 0.0644 - val_acc: 0.9804\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0670 - val_acc: 0.9801\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0727 - val_acc: 0.9799\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0033 - acc: 0.9998 - val_loss: 0.0676 - val_acc: 0.9801\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.0734 - val_acc: 0.9806\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0942 - val_acc: 0.9770\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0690 - val_acc: 0.9816\n",
      "Model 12 of 21. Hyperparams: Nadam, tanh\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3022 - acc: 0.9111 - val_loss: 0.1683 - val_acc: 0.9503\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1384 - acc: 0.9587 - val_loss: 0.1217 - val_acc: 0.9643\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0857 - acc: 0.9746 - val_loss: 0.0916 - val_acc: 0.9733\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0586 - acc: 0.9823 - val_loss: 0.0893 - val_acc: 0.9709\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0416 - acc: 0.9874 - val_loss: 0.0724 - val_acc: 0.9777\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0290 - acc: 0.9916 - val_loss: 0.0830 - val_acc: 0.9737\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0208 - acc: 0.9940 - val_loss: 0.0707 - val_acc: 0.9788\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0146 - acc: 0.9964 - val_loss: 0.0732 - val_acc: 0.9778\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0103 - acc: 0.9975 - val_loss: 0.0697 - val_acc: 0.9794\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0784 - val_acc: 0.9775\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0827 - val_acc: 0.9780\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0804 - val_acc: 0.9785\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0753 - val_acc: 0.9793\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0829 - val_acc: 0.9778\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0772 - val_acc: 0.9797\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0888 - val_acc: 0.9770\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0800 - val_acc: 0.9815\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0822 - val_acc: 0.9808\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0840 - val_acc: 0.9814\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0796 - val_acc: 0.9818\n",
      "Model 13 of 21. Hyperparams: Adamax, tanh\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3467 - acc: 0.8999 - val_loss: 0.2558 - val_acc: 0.9272\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2245 - acc: 0.9362 - val_loss: 0.1854 - val_acc: 0.9462\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1656 - acc: 0.9534 - val_loss: 0.1453 - val_acc: 0.9573\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1260 - acc: 0.9640 - val_loss: 0.1159 - val_acc: 0.9656\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0983 - acc: 0.9721 - val_loss: 0.0986 - val_acc: 0.9707\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0794 - acc: 0.9775 - val_loss: 0.0918 - val_acc: 0.9710\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0651 - acc: 0.9821 - val_loss: 0.0782 - val_acc: 0.9755\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0539 - acc: 0.9851 - val_loss: 0.0739 - val_acc: 0.9757\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0457 - acc: 0.9876 - val_loss: 0.0694 - val_acc: 0.9789\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0385 - acc: 0.9895 - val_loss: 0.0688 - val_acc: 0.9787\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0318 - acc: 0.9919 - val_loss: 0.0656 - val_acc: 0.9792\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0276 - acc: 0.9932 - val_loss: 0.0637 - val_acc: 0.9802\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0231 - acc: 0.9949 - val_loss: 0.0599 - val_acc: 0.9805\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0190 - acc: 0.9961 - val_loss: 0.0585 - val_acc: 0.9819\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0163 - acc: 0.9969 - val_loss: 0.0581 - val_acc: 0.9817\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0138 - acc: 0.9975 - val_loss: 0.0583 - val_acc: 0.9820\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0117 - acc: 0.9980 - val_loss: 0.0581 - val_acc: 0.9815\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0098 - acc: 0.9988 - val_loss: 0.0577 - val_acc: 0.9831\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0082 - acc: 0.9990 - val_loss: 0.0591 - val_acc: 0.9822\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0071 - acc: 0.9992 - val_loss: 0.0580 - val_acc: 0.9824\n",
      "Model 14 of 21. Hyperparams: SGD, tanh\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.9360 - acc: 0.7836 - val_loss: 0.5425 - val_acc: 0.8683\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4969 - acc: 0.8719 - val_loss: 0.4250 - val_acc: 0.8879\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4217 - acc: 0.8864 - val_loss: 0.3781 - val_acc: 0.8983\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3856 - acc: 0.8940 - val_loss: 0.3530 - val_acc: 0.9036\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3634 - acc: 0.8986 - val_loss: 0.3366 - val_acc: 0.9092\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3479 - acc: 0.9023 - val_loss: 0.3240 - val_acc: 0.9123\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3362 - acc: 0.9050 - val_loss: 0.3146 - val_acc: 0.9153\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3268 - acc: 0.9077 - val_loss: 0.3072 - val_acc: 0.9154\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3191 - acc: 0.9099 - val_loss: 0.3006 - val_acc: 0.9169\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3124 - acc: 0.9120 - val_loss: 0.2971 - val_acc: 0.9183\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3065 - acc: 0.9134 - val_loss: 0.2926 - val_acc: 0.9184\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3016 - acc: 0.9148 - val_loss: 0.2870 - val_acc: 0.9204\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2970 - acc: 0.9161 - val_loss: 0.2837 - val_acc: 0.9208\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2927 - acc: 0.9175 - val_loss: 0.2802 - val_acc: 0.9221\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2888 - acc: 0.9187 - val_loss: 0.2776 - val_acc: 0.9218\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2852 - acc: 0.9195 - val_loss: 0.2749 - val_acc: 0.9228\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2815 - acc: 0.9209 - val_loss: 0.2713 - val_acc: 0.9245\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2783 - acc: 0.9215 - val_loss: 0.2690 - val_acc: 0.9250\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2752 - acc: 0.9225 - val_loss: 0.2670 - val_acc: 0.9256\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2722 - acc: 0.9237 - val_loss: 0.2639 - val_acc: 0.9263\n",
      "Model 15 of 21. Hyperparams: rmsprop, relu\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2573 - acc: 0.9252 - val_loss: 0.1453 - val_acc: 0.9564\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1026 - acc: 0.9694 - val_loss: 0.0868 - val_acc: 0.9733\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0677 - acc: 0.9796 - val_loss: 0.0777 - val_acc: 0.9751\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0486 - acc: 0.9851 - val_loss: 0.0729 - val_acc: 0.9774\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0369 - acc: 0.9891 - val_loss: 0.0630 - val_acc: 0.9817\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0280 - acc: 0.9917 - val_loss: 0.0618 - val_acc: 0.9820\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0212 - acc: 0.9936 - val_loss: 0.0669 - val_acc: 0.9802\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0167 - acc: 0.9949 - val_loss: 0.0740 - val_acc: 0.9815\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.0670 - val_acc: 0.9826\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0746 - val_acc: 0.9808\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.0703 - val_acc: 0.9829\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0791 - val_acc: 0.9813\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0760 - val_acc: 0.9823\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0795 - val_acc: 0.9833\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0860 - val_acc: 0.9816\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0888 - val_acc: 0.9814\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0991 - val_acc: 0.9809\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0892 - val_acc: 0.9817\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0901 - val_acc: 0.9833\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0948 - val_acc: 0.9808\n",
      "Model 16 of 21. Hyperparams: adagrad, relu\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2416 - acc: 0.9301 - val_loss: 0.1380 - val_acc: 0.9601\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1194 - acc: 0.9665 - val_loss: 0.1090 - val_acc: 0.9679\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0922 - acc: 0.9746 - val_loss: 0.0950 - val_acc: 0.9708\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0760 - acc: 0.9791 - val_loss: 0.0859 - val_acc: 0.9744\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0652 - acc: 0.9827 - val_loss: 0.0799 - val_acc: 0.9754\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0571 - acc: 0.9845 - val_loss: 0.0751 - val_acc: 0.9776\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0509 - acc: 0.9866 - val_loss: 0.0729 - val_acc: 0.9788\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0460 - acc: 0.9883 - val_loss: 0.0695 - val_acc: 0.9786\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0418 - acc: 0.9892 - val_loss: 0.0677 - val_acc: 0.9797\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0381 - acc: 0.9905 - val_loss: 0.0655 - val_acc: 0.9802\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0352 - acc: 0.9917 - val_loss: 0.0642 - val_acc: 0.9802\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0324 - acc: 0.9928 - val_loss: 0.0634 - val_acc: 0.9798\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0302 - acc: 0.9935 - val_loss: 0.0620 - val_acc: 0.9804\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0280 - acc: 0.9942 - val_loss: 0.0627 - val_acc: 0.9801\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0262 - acc: 0.9949 - val_loss: 0.0613 - val_acc: 0.9816\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0245 - acc: 0.9953 - val_loss: 0.0614 - val_acc: 0.9813\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0231 - acc: 0.9957 - val_loss: 0.0601 - val_acc: 0.9811\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0216 - acc: 0.9963 - val_loss: 0.0595 - val_acc: 0.9819\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0204 - acc: 0.9965 - val_loss: 0.0596 - val_acc: 0.9811\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0194 - acc: 0.9970 - val_loss: 0.0585 - val_acc: 0.9818\n",
      "Model 17 of 21. Hyperparams: adadelta, relu\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2933 - acc: 0.9165 - val_loss: 0.1574 - val_acc: 0.9544\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1270 - acc: 0.9634 - val_loss: 0.1026 - val_acc: 0.9698\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0873 - acc: 0.9749 - val_loss: 0.0816 - val_acc: 0.9762\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0657 - acc: 0.9815 - val_loss: 0.0763 - val_acc: 0.9770\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0517 - acc: 0.9857 - val_loss: 0.0706 - val_acc: 0.9785\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0416 - acc: 0.9885 - val_loss: 0.0700 - val_acc: 0.9799\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0340 - acc: 0.9909 - val_loss: 0.0621 - val_acc: 0.9823\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0275 - acc: 0.9929 - val_loss: 0.0640 - val_acc: 0.9805\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0232 - acc: 0.9937 - val_loss: 0.0579 - val_acc: 0.9818\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0189 - acc: 0.9956 - val_loss: 0.0588 - val_acc: 0.9813\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0153 - acc: 0.9969 - val_loss: 0.0573 - val_acc: 0.9833\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0127 - acc: 0.9977 - val_loss: 0.0546 - val_acc: 0.9839\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0105 - acc: 0.9983 - val_loss: 0.0584 - val_acc: 0.9828\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0087 - acc: 0.9988 - val_loss: 0.0579 - val_acc: 0.9829\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.0569 - val_acc: 0.9840\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0059 - acc: 0.9994 - val_loss: 0.0561 - val_acc: 0.9845\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0571 - val_acc: 0.9839\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0574 - val_acc: 0.9841\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0035 - acc: 0.9998 - val_loss: 0.0570 - val_acc: 0.9843\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.0569 - val_acc: 0.9846\n",
      "Model 18 of 21. Hyperparams: adam, relu\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2666 - acc: 0.9246 - val_loss: 0.1356 - val_acc: 0.9608\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1101 - acc: 0.9680 - val_loss: 0.0933 - val_acc: 0.9711\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0707 - acc: 0.9794 - val_loss: 0.0751 - val_acc: 0.9760\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0505 - acc: 0.9851 - val_loss: 0.0697 - val_acc: 0.9777\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0367 - acc: 0.9894 - val_loss: 0.0792 - val_acc: 0.9745\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0286 - acc: 0.9918 - val_loss: 0.0621 - val_acc: 0.9793\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0203 - acc: 0.9945 - val_loss: 0.0652 - val_acc: 0.9802\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0160 - acc: 0.9957 - val_loss: 0.0653 - val_acc: 0.9798\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0118 - acc: 0.9971 - val_loss: 0.0631 - val_acc: 0.9797\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.0653 - val_acc: 0.9795\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0607 - val_acc: 0.9817\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0674 - val_acc: 0.9802\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.0690 - val_acc: 0.9808\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0057 - acc: 0.9986 - val_loss: 0.0785 - val_acc: 0.9793\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0817 - val_acc: 0.9800\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0766 - val_acc: 0.9816\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0660 - val_acc: 0.9809\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0644 - val_acc: 0.9837\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9819\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0946 - val_acc: 0.9778\n",
      "Model 19 of 21. Hyperparams: Nadam, relu\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2204 - acc: 0.9360 - val_loss: 0.1073 - val_acc: 0.9672\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0808 - acc: 0.9759 - val_loss: 0.1002 - val_acc: 0.9662\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0505 - acc: 0.9842 - val_loss: 0.0725 - val_acc: 0.9758\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0346 - acc: 0.9895 - val_loss: 0.0657 - val_acc: 0.9794\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0261 - acc: 0.9920 - val_loss: 0.0627 - val_acc: 0.9811\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0185 - acc: 0.9944 - val_loss: 0.0696 - val_acc: 0.9798\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0699 - val_acc: 0.9799\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0708 - val_acc: 0.9833\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0860 - val_acc: 0.9786\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0097 - acc: 0.9965 - val_loss: 0.0760 - val_acc: 0.9805\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0816 - val_acc: 0.9798\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0122 - acc: 0.9960 - val_loss: 0.0864 - val_acc: 0.9816\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0089 - acc: 0.9968 - val_loss: 0.0928 - val_acc: 0.9788\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0998 - val_acc: 0.9783\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0934 - val_acc: 0.9796\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0945 - val_acc: 0.9802\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0976 - val_acc: 0.9810\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0900 - val_acc: 0.9827\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.1088 - val_acc: 0.9792\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.1068 - val_acc: 0.9792\n",
      "Model 20 of 21. Hyperparams: Adamax, relu\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2869 - acc: 0.9209 - val_loss: 0.1691 - val_acc: 0.9508\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1416 - acc: 0.9594 - val_loss: 0.1194 - val_acc: 0.9646\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0998 - acc: 0.9710 - val_loss: 0.0934 - val_acc: 0.9721\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0760 - acc: 0.9786 - val_loss: 0.0909 - val_acc: 0.9711\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0598 - acc: 0.9829 - val_loss: 0.0739 - val_acc: 0.9773\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0483 - acc: 0.9864 - val_loss: 0.0728 - val_acc: 0.9773\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0394 - acc: 0.9895 - val_loss: 0.0676 - val_acc: 0.9806\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0330 - acc: 0.9914 - val_loss: 0.0627 - val_acc: 0.9798\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0272 - acc: 0.9932 - val_loss: 0.0621 - val_acc: 0.9800\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0227 - acc: 0.9948 - val_loss: 0.0581 - val_acc: 0.9815\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0187 - acc: 0.9961 - val_loss: 0.0579 - val_acc: 0.9814\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0160 - acc: 0.9966 - val_loss: 0.0574 - val_acc: 0.9808\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0131 - acc: 0.9977 - val_loss: 0.0563 - val_acc: 0.9821\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0105 - acc: 0.9986 - val_loss: 0.0568 - val_acc: 0.9820\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0088 - acc: 0.9990 - val_loss: 0.0566 - val_acc: 0.9829\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0076 - acc: 0.9991 - val_loss: 0.0573 - val_acc: 0.9821\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0062 - acc: 0.9995 - val_loss: 0.0602 - val_acc: 0.9820\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0608 - val_acc: 0.9826\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.0584 - val_acc: 0.9831\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0037 - acc: 0.9997 - val_loss: 0.0593 - val_acc: 0.9827\n",
      "Model 21 of 21. Hyperparams: SGD, relu\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.1120 - acc: 0.7526 - val_loss: 0.6014 - val_acc: 0.8668\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.5206 - acc: 0.8737 - val_loss: 0.4313 - val_acc: 0.8899\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.4177 - acc: 0.8912 - val_loss: 0.3705 - val_acc: 0.9022\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3712 - acc: 0.9005 - val_loss: 0.3366 - val_acc: 0.9090\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3426 - acc: 0.9065 - val_loss: 0.3149 - val_acc: 0.9142\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3222 - acc: 0.9117 - val_loss: 0.2987 - val_acc: 0.9183\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3063 - acc: 0.9154 - val_loss: 0.2863 - val_acc: 0.9225\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2933 - acc: 0.9193 - val_loss: 0.2753 - val_acc: 0.9257\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2821 - acc: 0.9219 - val_loss: 0.2658 - val_acc: 0.9285\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2723 - acc: 0.9251 - val_loss: 0.2577 - val_acc: 0.9295\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2636 - acc: 0.9271 - val_loss: 0.2496 - val_acc: 0.9318\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2555 - acc: 0.9291 - val_loss: 0.2437 - val_acc: 0.9328\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2484 - acc: 0.9316 - val_loss: 0.2378 - val_acc: 0.9345\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2417 - acc: 0.9334 - val_loss: 0.2310 - val_acc: 0.9366\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2353 - acc: 0.9351 - val_loss: 0.2256 - val_acc: 0.9382\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2292 - acc: 0.9371 - val_loss: 0.2206 - val_acc: 0.9397\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2236 - acc: 0.9382 - val_loss: 0.2163 - val_acc: 0.9403\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2184 - acc: 0.9403 - val_loss: 0.2111 - val_acc: 0.9420\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2133 - acc: 0.9416 - val_loss: 0.2071 - val_acc: 0.9433\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2087 - acc: 0.9431 - val_loss: 0.2026 - val_acc: 0.9437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define parameter grid\n",
    "activation_functions_layer_1 = ['sigmoid','tanh','relu']\n",
    "optimizers = ['rmsprop','adagrad','adadelta','adam','Nadam','Adamax','SGD']\n",
    "num_hyperparams = len(optimizers)*len(activation_functions_layer_1)\n",
    "counter = 1\n",
    "df = pd.DataFrame(columns=['optimizers','activation_functions_layer_1','score','file name'])\n",
    "\n",
    "# optimize over parameter grid (grid search)\n",
    "for activation_function_layer_1 in activation_functions_layer_1:\n",
    "    for optimizer in optimizers:\n",
    "        print('Model %s of %s. Hyperparams: %s, %s' % (counter, num_hyperparams, optimizer, activation_function_layer_1))\n",
    "        counter = counter+1\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation = activation_function_layer_1, input_shape=(784,)))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "        \n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        save_path = \"ker_func_mnist_model_2.%s.%s.%s.h5\" % (activation_function_layer_1,optimizer,score[1])\n",
    "        model.save(save_path)\n",
    "        \n",
    "        df = df.append({'activation_functions_layer_1' : activation_function_layer_1,'optimizers': optimizer, 'score' : score[1], 'file name': save_path}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "Let's have a look at all the models and see which hyper parameter configuration was the best one. We can see that the majority of hyper parameter combinations yield >95% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizers</th>\n",
       "      <th>activation_functions_layer_1</th>\n",
       "      <th>score</th>\n",
       "      <th>file name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>adadelta</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>ker_func_mnist_model_2.relu.adadelta.0.9846.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>ker_func_mnist_model_2.tanh.rmsprop.0.9829.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adamax</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>ker_func_mnist_model_2.relu.Adamax.0.9827.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>ker_func_mnist_model_2.sigmoid.rmsprop.0.9826.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adadelta</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>ker_func_mnist_model_2.tanh.adadelta.0.9824.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adamax</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>ker_func_mnist_model_2.tanh.Adamax.0.9824.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>adagrad</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>ker_func_mnist_model_2.relu.adagrad.0.9818.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nadam</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>ker_func_mnist_model_2.tanh.Nadam.0.9818.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adam</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>ker_func_mnist_model_2.tanh.adam.0.9816.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>ker_func_mnist_model_2.sigmoid.adam.0.9809.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>ker_func_mnist_model_2.relu.rmsprop.0.9808.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adamax</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.9796</td>\n",
       "      <td>ker_func_mnist_model_2.sigmoid.Adamax.0.9796.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nadam</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>ker_func_mnist_model_2.relu.Nadam.0.9792.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nadam</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>ker_func_mnist_model_2.sigmoid.Nadam.0.9791.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9778</td>\n",
       "      <td>ker_func_mnist_model_2.relu.adam.0.9778.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adagrad</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>ker_func_mnist_model_2.tanh.adagrad.0.9747.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adadelta</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>ker_func_mnist_model_2.sigmoid.adadelta.0.9747.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adagrad</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>ker_func_mnist_model_2.sigmoid.adagrad.0.9618.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>ker_func_mnist_model_2.relu.SGD.0.9437.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGD</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>ker_func_mnist_model_2.tanh.SGD.0.9263.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>ker_func_mnist_model_2.sigmoid.SGD.0.8999.h5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   optimizers activation_functions_layer_1   score  \\\n",
       "16   adadelta                         relu  0.9846   \n",
       "7     rmsprop                         tanh  0.9829   \n",
       "19     Adamax                         relu  0.9827   \n",
       "0     rmsprop                      sigmoid  0.9826   \n",
       "9    adadelta                         tanh  0.9824   \n",
       "12     Adamax                         tanh  0.9824   \n",
       "15    adagrad                         relu  0.9818   \n",
       "11      Nadam                         tanh  0.9818   \n",
       "10       adam                         tanh  0.9816   \n",
       "3        adam                      sigmoid  0.9809   \n",
       "14    rmsprop                         relu  0.9808   \n",
       "5      Adamax                      sigmoid  0.9796   \n",
       "18      Nadam                         relu  0.9792   \n",
       "4       Nadam                      sigmoid  0.9791   \n",
       "17       adam                         relu  0.9778   \n",
       "8     adagrad                         tanh  0.9747   \n",
       "2    adadelta                      sigmoid  0.9747   \n",
       "1     adagrad                      sigmoid  0.9618   \n",
       "20        SGD                         relu  0.9437   \n",
       "13        SGD                         tanh  0.9263   \n",
       "6         SGD                      sigmoid  0.8999   \n",
       "\n",
       "                                            file name  \n",
       "16     ker_func_mnist_model_2.relu.adadelta.0.9846.h5  \n",
       "7       ker_func_mnist_model_2.tanh.rmsprop.0.9829.h5  \n",
       "19       ker_func_mnist_model_2.relu.Adamax.0.9827.h5  \n",
       "0    ker_func_mnist_model_2.sigmoid.rmsprop.0.9826.h5  \n",
       "9      ker_func_mnist_model_2.tanh.adadelta.0.9824.h5  \n",
       "12       ker_func_mnist_model_2.tanh.Adamax.0.9824.h5  \n",
       "15      ker_func_mnist_model_2.relu.adagrad.0.9818.h5  \n",
       "11        ker_func_mnist_model_2.tanh.Nadam.0.9818.h5  \n",
       "10         ker_func_mnist_model_2.tanh.adam.0.9816.h5  \n",
       "3       ker_func_mnist_model_2.sigmoid.adam.0.9809.h5  \n",
       "14      ker_func_mnist_model_2.relu.rmsprop.0.9808.h5  \n",
       "5     ker_func_mnist_model_2.sigmoid.Adamax.0.9796.h5  \n",
       "18        ker_func_mnist_model_2.relu.Nadam.0.9792.h5  \n",
       "4      ker_func_mnist_model_2.sigmoid.Nadam.0.9791.h5  \n",
       "17         ker_func_mnist_model_2.relu.adam.0.9778.h5  \n",
       "8       ker_func_mnist_model_2.tanh.adagrad.0.9747.h5  \n",
       "2   ker_func_mnist_model_2.sigmoid.adadelta.0.9747.h5  \n",
       "1    ker_func_mnist_model_2.sigmoid.adagrad.0.9618.h5  \n",
       "20          ker_func_mnist_model_2.relu.SGD.0.9437.h5  \n",
       "13          ker_func_mnist_model_2.tanh.SGD.0.9263.h5  \n",
       "6        ker_func_mnist_model_2.sigmoid.SGD.0.8999.h5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by=['score'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for deployment\n",
    "\n",
    "Now it's time to create a tarball out of the best performing model. This tarball can be sent to Cloud clients such as IBM Watson ML and deployed from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a ker_func_mnist_model_2.relu.adadelta.0.9846.h5\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf my_best_model.tgz ker_func_mnist_model_2.relu.adadelta.0.9846.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
