{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection - Haar Cascades and NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import Model, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Data\n",
    "### MobileNet Single Shot SSD files\n",
    "Pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "out_dir = f'{os.getcwd()}\\\\Data\\\\facemask_data'\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/deploy.prototxt'\n",
    "localnetworkfile = out_dir + '\\\\deploy.prototxt'\n",
    "\n",
    "if os.path.exists(localnetworkfile):\n",
    "    print(\"File exists\")\n",
    "else:\n",
    "    wget.download(url, out=out_dir)\n",
    "    print(\"Download Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/mobilenet_iter_73000.caffemodel'\n",
    "localcaffe = out_dir + '\\\\mobilenet_iter_73000.caffemodel'\n",
    "\n",
    "if os.path.exists(localcaffe):\n",
    "    print(\"File exists\")\n",
    "else:\n",
    "    wget.download(url, out=out_dir)\n",
    "    print(\"Download Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Pre-Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream open.\n"
     ]
    }
   ],
   "source": [
    "# Labels of Network.\n",
    "classNames = { 0: 'background',\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }\n",
    "\n",
    "# Capture accesses the video feed. The \"0\" is the number of your video device, in case you have multiple.\n",
    "cap = cv2.VideoCapture(0)\n",
    "if cap.isOpened() == True:\n",
    "    print(\"Video stream open.\")\n",
    "else:\n",
    "    print(\"Problem opening video stream.\")\n",
    "\n",
    "#Load the Caffe model \n",
    "net = cv2.dnn.readNetFromCaffe(localnetworkfile, localcaffe)\n",
    "\n",
    "# load the best face mask model\n",
    "mask_model = load_model(out_dir+\"./model1-006.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Start Camera Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "497\n",
      "478\n",
      "138\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 22500 into shape (1,150,150,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d6ed5d05b916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m                     \u001b[0mrerect_sized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                     \u001b[0mnormalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrerect_sized\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                     \u001b[0mreshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                     \u001b[0mreshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreshaped\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    299\u001b[0m            [5, 6]])\n\u001b[0;32m    300\u001b[0m     \"\"\"\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 22500 into shape (1,150,150,3)"
     ]
    }
   ],
   "source": [
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        frame_resized = cv2.resize(frame,(300,300)) # resize frame for prediction\n",
    "\n",
    "        # MobileNet requires fixed dimensions for input image(s)\n",
    "        # so we have to ensure that it is resized to 300x300 pixels.\n",
    "        # set a scale factor to image because network the objects has differents size. \n",
    "        # We perform a mean subtraction (127.5, 127.5, 127.5) to normalize the input;\n",
    "        # after executing this command our \"blob\" now has the shape:\n",
    "        # (1, 3, 300, 300)\n",
    "        blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5, 127.5, 127.5), False)\n",
    "        #Set to network the input blob \n",
    "        net.setInput(blob)\n",
    "        \n",
    "        # Prediction of Mobilenet\n",
    "        detections = net.forward()\n",
    "\n",
    "        #Size of frame resize (300x300)\n",
    "        cols = frame_resized.shape[1] \n",
    "        rows = frame_resized.shape[0]\n",
    "\n",
    "        #For get the class and location of object detected, \n",
    "        # There is a fix index for class, location and confidence\n",
    "        # value in @detections array .\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2] # Confidence of prediction\n",
    "            if confidence > 0.2: # Filter prediction\n",
    "                class_id = int(detections[0, 0, i, 1]) # Class label\n",
    "\n",
    "                # Object location\n",
    "                xLeftBottom = int(detections[0, 0, i, 3] * cols)\n",
    "                yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "                xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "                yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "\n",
    "                # Factor for scale to original size of frame\n",
    "                heightFactor = frame.shape[0]/300.0\n",
    "                widthFactor = frame.shape[1]/300.0\n",
    "                # Scale object detection to frame\n",
    "                xLeftBottom = int(widthFactor * xLeftBottom)\n",
    "                yLeftBottom = int(heightFactor * yLeftBottom)\n",
    "                xRightTop   = int(widthFactor * xRightTop)\n",
    "                yRightTop   = int(heightFactor * yRightTop)\n",
    "                \n",
    "                height = yRightTop - yLeftBottom\n",
    "                width = xRightTop - xLeftBottom\n",
    "                print(height)\n",
    "                print(width)\n",
    "                y = yLeftBottom\n",
    "                x = xRightTop\n",
    "                print(y)\n",
    "                print(x)\n",
    "\n",
    "                # Draw location of object  \n",
    "                #cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop), (0, 255, 0))\n",
    "\n",
    "                # grab the scaled image content of the bounding box for later\n",
    "                #persons = frame[yLeftBottom:yRightTop, xLeftBottom:xRightTop]\n",
    "\n",
    "                # Draw label and confidence of prediction in frame resized\n",
    "                if class_id == 15:\n",
    "\n",
    "                    # draw rectangle around detected persons\n",
    "                    cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop), (0, 255, 0))\n",
    "                    mobilenetlabel = classNames[class_id] + \": \" + str(confidence)\n",
    "                    #labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "                    # grab the scaled image content of the bounding box for mask network\n",
    "                    persons = frame[y:y+height, x:x+width]\n",
    "                    #persons = frame[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # pass the person image into the face mask prediction\n",
    "                    for person in persons:\n",
    "                        rerect_sized = cv2.resize(person,(150,150))\n",
    "                        normalized = rerect_sized/255.0\n",
    "                        reshaped = np.reshape(normalized,(1,150,150,3))\n",
    "                        reshaped = np.vstack([reshaped])\n",
    "                        result = mask_model.predict(reshaped)\n",
    "\n",
    "                        masklabel = np.argmax(result,axis=1)[0]\n",
    "                        # assemble label text\n",
    "                        label = str(mobilnetlabel) + str(results[masklabel])\n",
    "                        \n",
    "                        # draw white boxes on top of persons\n",
    "                        yLeftBottom = max(yLeftBottom, labelSize[1])\n",
    "                        cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]), xLeftBottom + labelSize[0], (yLeftBottom + baseLine),(255, 255, 255), cv2.FILLED)\n",
    "                        # draw boxes???\n",
    "                        cv2.rectangle(frame,(x,y),(x+w,y+h),GR_dict[label],2)\n",
    "                        cv2.rectangle(frame,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
    "                        # draw assembled label\n",
    "                        cv2.putText(frame, label, (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "                        print('bla')\n",
    "                    \n",
    "\n",
    "                    \n",
    "        cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) >= 0:  # Break with any key \n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # pass the person image into the second neural network for face mask prediction\n",
    "                    for person in persons:\n",
    "                        rerect_sized = cv2.resize(person,(150,150))\n",
    "                        normalized = rerect_sized/255.0\n",
    "                        reshaped = np.reshape(normalized,(1,150,150,3))\n",
    "                        reshaped = np.vstack([reshaped])\n",
    "                        result = mask_model.predict(reshaped)\n",
    "\n",
    "                        masklabel = np.argmax(result,axis=1)[0]\n",
    "                        # assemble label text\n",
    "                        label = str(mobilnetlabel) + str(results[masklabel])\n",
    "                        \n",
    "                        # draw white boxes on top of persons\n",
    "                        yLeftBottom = max(yLeftBottom, labelSize[1])\n",
    "                        cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]),\n",
    "                                      xLeftBottom + labelSize[0], yLeftBottom + baseLine),\n",
    "                                      (255, 255, 255), cv2.FILLED)\n",
    "                        # draw boxes???\n",
    "                        cv2.rectangle(frame,(x,y),(x+w,y+h),GR_dict[label],2)\n",
    "                        cv2.rectangle(frame,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
    "                        # draw assembled label\n",
    "                        cv2.putText(frame, label, (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
